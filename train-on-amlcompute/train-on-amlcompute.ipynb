{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596404498981",
   "display_name": "Python 3.6.10 64-bit ('vienna': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on AML Compute\n",
    "\n",
    "Train MLflow Projects on Azure Machine Learning Compute.\n",
    "\n",
    "## Table of Contents\n",
    "1. Prerequisites\n",
    "    - 1.1 Initialize Tracking Store and Experiment\n",
    "    - 1.2 Configure the Backend Configuration object\n",
    "    - 1.3 Modify your Environment specification\n",
    "3. Submit Run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites \n",
    "Ensure you have done the following before running this notebook,\n",
    "- Connected to an AML Workspace\n",
    "- Have an existing Compute cluster in that Workspace\n",
    "- Have an MLproject file with an environment specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prereq Checks\n",
    "\n",
    "# Workspace check\n",
    "from azureml.core import Workspace\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, sep = '\\n')\n",
    "\n",
    "# Existing compute check\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace = workspace, name = cpu_cluster_name)\n",
    "    print(\"Found existing cluster, yay!\")\n",
    "except ComputeTargetException:\n",
    "    print(\"This compute target is not associated with your workspace!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tracking Store and Experiment\n",
    "\n",
    "### Set Tracking URI \n",
    "\n",
    "Set the MLflow tracking URI to point to your Azure ML Workspace. The subsequent logging calls from MLflow APIs will go to Azure ML services and will be tracked under your Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml import core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "import mlflow\n",
    "\n",
    "workspace = Workspace.from_config()  \n",
    "mlflow.set_tracking_uri(workspace.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "\n",
    "Create an Mlflow Experiment to organize your runs. It can be set either by passing the name as a **parameter** in the mlflow.projects.run call or by the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"mlflow-example\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Backend Configuration Object\n",
    "\n",
    "The backend configuration object will store necesary information for the integration such as the compute target and whether to use your local managed environment or a system managed environment. \n",
    "\n",
    "The integration will accept \"COMPUTE\" and \"USE_CONDA\" as parameters where \"COMPUTE\" is set to the name of your remote compute cluster and \"USE_CONDA\" which creates a new environment for the project from the environment configuration file. If \"COMPUTE\" is present in the object, the project will be automatically submitted to the remote compute and ignore \"USE_CONDA\". Mlflow accepts a dictionary object or a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "backend_config = {\"COMPUTE\": \"cpu-cluster\", \"USE_CONDA\": False}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify your Environment specification\n",
    "\n",
    "Add the azureml-mlflow package as a pip dependency to your environment configuration file. The project can run without this addition, but key artifacts and metrics will not be logged to your Workspace. Adding it to to the file will look like this,\n",
    "\n",
    "```\n",
    "name: mlflow-example\n",
    "channels:\n",
    "  - defaults\n",
    "  - anaconda\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - scikit-learn=0.19.1\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow\n",
    "    - azureml-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Run \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_mlflow_run = mlflow.projects.run(uri=\".\", \n",
    "                                    parameters={\"alpha\":0.3},\n",
    "                                    backend = \"azureml\",\n",
    "                                    backend_config = backend_config)"
   ]
  }
 ]
}