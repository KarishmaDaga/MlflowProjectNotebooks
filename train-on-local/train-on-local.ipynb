{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596403192908",
   "display_name": "Python 3.6.10 64-bit ('vienna': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train locally\n",
    "\n",
    "Train an MLflow Project directly on your machine using local compute and AzureML SDK.\n",
    "\n",
    "## Table of Contents\n",
    "1. Prerequisites\n",
    "    - 1.1 Initialize Tracking Store and Experiment\n",
    "    - 1.2 Configure the Backend Configuration object\n",
    "    - 1.3 Modify your Environment specification\n",
    "2. Submit Run\n",
    "    - 2.1 User-managed environment\n",
    "    - 2.2 System-managed environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites \n",
    "Ensure you have done the following before running this notebook,\n",
    "- Connected to an AML Workspace\n",
    "- Your local conda environment has the necessary packages needed to run this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tracking Store and Experiment\n",
    "\n",
    "### Set the Tracking Store\n",
    "Set the MLflow tracking URI to point to your Azure ML Workspace. The subsequent logging calls from MLflow APIs will go to Azure ML services and will be tracked under your Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml import core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "import mlflow\n",
    "\n",
    "workspace = Workspace.from_config()  \n",
    "mlflow.set_tracking_uri(workspace.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "Create an Mlflow Experiment to organize your runs. It can be set either by passing the name as a parameter in the mlflow.projects.run call or by the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"mlflow-example\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Backend Configuration Object\n",
    "\n",
    "The backend configuration object will store necesary information for the integration such as the compute target and whether to use your local managed environment or a system managed environment. \n",
    "\n",
    "The integration will accept \"COMPUTE\" and \"USE_CONDA\" as parameters where \"COMPUTE\" is set to the name of a remote target (not applicable for this training example) and \"USE_CONDA\" which creates a new environment for the project from the environment configuration file. You must set this to \"False\" and include it in the backend configuration object if you want to use your local environment for the project run. Mlflow accepts a dictionary object or a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "backend_config = {\"USE_CONDA\": False}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the Integration to your Environment Configuration\n",
    "\n",
    "Add the azureml-mlflow package as a pip dependency to your environment configuration file. The project can run without this addition, but key artifacts and metrics will not be logged to your Workspace. Adding it to to the file will look like this,\n",
    "\n",
    "```\n",
    "name: mlflow-example\n",
    "channels:\n",
    "  - defaults\n",
    "  - anaconda\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - scikit-learn=0.19.1\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow\n",
    "    - azureml-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Managed environment\n",
    "For using your local conda environment, set `use_conda = False`. Ensure your local environment has all the necessary packages for running the project and you are specifying the **backend parameter** in any run call to be **\"azureml\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_env_run = mlflow.projects.run(uri=\".\", \n",
    "                                    parameters={\"alpha\":0.3},\n",
    "                                    backend = \"azureml\",\n",
    "                                    backend_config = backend_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: All these calculations were run on your local machine, in the conda environment you defined above. You can find the results in:\n",
    "- Your AzureML Experiments (a link to the run will be provided in the console)\n",
    "- ~/.azureml/envs/azureml_xxxx for the conda environment you just created\n",
    "- ~/AppData/Local/Temp/azureml_runs/train-on-local_xxxx for the machine learning models you trained (this path may differ depending on the platform you use). This folder also contains\n",
    "    - Logs (under azureml_logs/)\n",
    "    - Output pickled files (under outputs/)\n",
    "    - The configuration files (credentials, local and docker image setups)\n",
    "    - The train.py and mylib.py scripts\n",
    "    - The current notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Mananged Environment\n",
    "\n",
    "Now, instead of managing the setup of the environment yourself, you can ask the system to build a new conda environment for you using the environment configuration file in this project. If a backend configuration object is not provided in the call, the integration will default to creating a new conda environment. The environment is built once, and will be reused in subsequent executions as long as the conda dependencies remain unchanged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "backend_config = {\"USE_CONDA\": True}\n",
    "local_mlproject_run = mlflow.projects.run(uri=\".\", \n",
    "                                    parameters={\"alpha\":0.3},\n",
    "                                    backend = \"azureml\",\n",
    "                                    backend_config = backend_config)"
   ]
  }
 ]
}