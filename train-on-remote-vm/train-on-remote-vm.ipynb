{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596403192908",
   "display_name": "Python 3.6.10 64-bit ('vienna': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Remote Virtual Machines\n",
    "\n",
    "Train MLflow Projects on remote DSVMs (Data Science Virtual Machines).\n",
    "\n",
    "## Table of Contents\n",
    "1. Prerequisites\n",
    "    - 1.1 Initialize Tracking Store and Experiment\n",
    "    - 1.2 Create and Attach DSVM \n",
    "    - 1.3 Configure the Backend Configuration object\n",
    "    - 1.4 Modify your Environment Specification\n",
    "3. Submit Run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites \n",
    "Ensure you have done the following before running this notebook,\n",
    "- Connected to an AML Workspace\n",
    "- Have an existing remote DSVM in that Workspace\n",
    "- Have an MLproject file with an environment specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prereq Checks\n",
    "\n",
    "# Workspace check\n",
    "from azureml.core import Workspace\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, sep = '\\n')\n",
    "\n",
    "# Existing DSVM check\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "dsvm_name = \"dsvm\"\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace = workspace, name = dsvm_name)\n",
    "    print(\"Found existing cluster, yay!\")\n",
    "except ComputeTargetException:\n",
    "    print(\"This compute target is not associated with your workspace!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Attach a DSVM as a Compute Target\n",
    "You can spin up a DSVM in two ways:\n",
    "\n",
    "1. Create a DSVM in your resource group using the following command\n",
    "```\n",
    "az vm create --resource-group <resource_group_name> --name <some_vm_name>\n",
    "--image microsoft-dsvm:linux-data-science-vm-ubuntu:linuxdsvmubuntu:latest\n",
    "--admin-username <username> --admin-password <password>\n",
    "--generate-ssh-keys --authentication-type password\n",
    "```\n",
    "2. Go to the [Azure Portal](https://ms.portal.azure.com/#home) and in the search bar, type \"Data Science Virtual Machine\". On the right under \"Marketplace\", there should be an option to select \"Data Science Virtual Machine - Ubuntu 18.04\". Select 'Create' and add the required information. Set the region to be in Central US EUAP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tracking Store and Experiment\n",
    "\n",
    "### Set Tracking URI\n",
    " \n",
    "Set the MLflow tracking URI to point to your Azure ML Workspace. The subsequent logging calls from MLflow APIs will go to Azure ML services and will be tracked under your Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml import core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "import mlflow\n",
    "\n",
    "workspace = Workspace.from_config()  \n",
    "mlflow.set_tracking_uri(workspace.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "\n",
    "Create an Mlflow Experiment to organize your runs. It can be set either by passing the name as a **parameter** in the mlflow.projects.run call or by the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"mlflow-example\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Backend Configuration Object\n",
    "\n",
    "The backend configuration object will store necesary information for the integration such as the compute target and whether to use your local managed environment or a system managed environment. \n",
    "\n",
    "The integration will accept \"COMPUTE\" and \"USE_CONDA\" as parameters where \"COMPUTE\" is set to the name of your remote compute cluster and \"USE_CONDA\" which creates a new environment for the project from the environment configuration file. If \"COMPUTE\" is present in the object, the project will be automatically submitted to the remote compute and ignore \"USE_CONDA\". Mlflow accepts a dictionary object or a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "backend_config = {\"COMPUTE\": \"dsvm\", \"USE_CONDA\": False}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify your Environment specification\n",
    "\n",
    "Add the azureml-mlflow package as a pip dependency to your environment configuration file. The project can run without this addition, but key artifacts and metrics will not be logged to your Workspace. Adding it to to the file will look like this,\n",
    "\n",
    "```\n",
    "name: mlflow-example\n",
    "channels:\n",
    "  - defaults\n",
    "  - anaconda\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - scikit-learn=0.19.1\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow\n",
    "    - azureml-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Run \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_mlflow_run = mlflow.projects.run(uri=\".\", \n",
    "                                    parameters={\"alpha\":0.3},\n",
    "                                    backend = \"azureml\",\n",
    "                                    backend_config = backend_config)"
   ]
  }
 ]
}